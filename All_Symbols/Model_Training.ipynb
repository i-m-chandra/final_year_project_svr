{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imchandra/Desktop/SVRNEW/All_Symbols\n"
     ]
    }
   ],
   "source": [
    "execution_path = os.getcwd()\n",
    "print(execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = pd.read_csv(os.path.join(execution_path, 'combined_2_signs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>134</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>138</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>134</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>129</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>136</td>\n",
       "      <td>93</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>138</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>136</td>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>1022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>136</td>\n",
       "      <td>91</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3   4   5   6   7     8  9  10  11  12\n",
       "0  0.35  0.94 -0.09  134  89  65  54  46  1023  0   1   1   1\n",
       "1  0.35  0.92 -0.08  136  87  65  49  48  1023  0   1   1   1\n",
       "2  0.33  0.95 -0.05  138  87  65  45  50  1022  0   1   1   1\n",
       "3  0.34  0.94 -0.08  134  89  67  49  52  1021  0   1   1   1\n",
       "4  0.35  0.94 -0.07  129  89  67  51  46  1022  0   1   1   1\n",
       "5  0.34  0.94 -0.08  136  93  65  51  43  1022  0   1   1   1\n",
       "6  0.33  0.94 -0.06  138  87  69  49  48  1022  0   1   1   1\n",
       "7  0.33  0.94 -0.06  136  87  64  51  50  1023  0   1   1   1\n",
       "8  0.34  0.93 -0.07  136  89  72  51  50  1022  0   1   1   1\n",
       "9  0.31  0.94 -0.07  136  91  67  53  48  1023  0   1   1   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 13)\n"
     ]
    }
   ],
   "source": [
    "X_numpy = combined_csv.values\n",
    "print(X_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000e+00 1.000e+00 1.000e+00 2.550e+02 2.550e+02 2.550e+02 2.550e+02\n",
      " 2.550e+02 1.023e+03 1.000e+00 1.000e+00 1.000e+00 1.000e+00]\n",
      "(3800, 13)\n"
     ]
    }
   ],
   "source": [
    "norm_array = np.array([1, 1, 1, 255.0, 255.0, 255.0, 255.0, 255.0, 1023.0, 1, 1, 1, 1])\n",
    "print(norm_array)\n",
    "\n",
    "normalized_X = X_numpy / norm_array[None, :]\n",
    "print(normalized_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35      ,  0.94      , -0.09      ,  0.5254902 ,  0.34901961,\n",
       "        0.25490196,  0.21176471,  0.18039216,  1.        ,  0.        ,\n",
       "        1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_labels = pd.read_csv(os.path.join(execution_path, \"combined_2_signs_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  29\n",
       "1  29\n",
       "2  29\n",
       "3  29\n",
       "4  29\n",
       "5  29\n",
       "6  29\n",
       "7  29\n",
       "8  29\n",
       "9  29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 1)\n",
      "(3800, 44)\n"
     ]
    }
   ],
   "source": [
    "Y_numpy = combined_csv_labels.values\n",
    "print(Y_numpy.shape)\n",
    "\n",
    "labels_one_hot = to_categorical(Y_numpy)\n",
    "print(labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 13)\n"
     ]
    }
   ],
   "source": [
    "final_dataset, final_labels = shuffle(normalized_X, labels_one_hot)\n",
    "\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3610, 13)\n",
      "(3610, 44)\n",
      "(190, 13)\n",
      "(190, 44)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(final_dataset, final_labels, test_size=0.05, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(input_shape = (13,), units = 44, activation = 'softmax'))\n",
    "\n",
    "#model.add(Dense(units = 8, activation = 'sigmoid'))\n",
    "\n",
    "model1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 44)                616       \n",
      "=================================================================\n",
      "Total params: 616\n",
      "Trainable params: 616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/imchandra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 3610 samples, validate on 190 samples\n",
      "Epoch 1/40\n",
      "3610/3610 [==============================] - 0s 64us/step - loss: 3.6699 - acc: 0.0704 - val_loss: 3.5553 - val_acc: 0.0632\n",
      "Epoch 2/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 3.4708 - acc: 0.1258 - val_loss: 3.3823 - val_acc: 0.1053\n",
      "Epoch 3/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 3.3052 - acc: 0.2119 - val_loss: 3.2330 - val_acc: 0.1737\n",
      "Epoch 4/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 3.1590 - acc: 0.2947 - val_loss: 3.1002 - val_acc: 0.3684\n",
      "Epoch 5/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 3.0242 - acc: 0.4770 - val_loss: 2.9707 - val_acc: 0.5526\n",
      "Epoch 6/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 2.8985 - acc: 0.5568 - val_loss: 2.8544 - val_acc: 0.6158\n",
      "Epoch 7/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 2.7809 - acc: 0.6338 - val_loss: 2.7422 - val_acc: 0.6895\n",
      "Epoch 8/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 2.6695 - acc: 0.7144 - val_loss: 2.6346 - val_acc: 0.7368\n",
      "Epoch 9/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 2.5639 - acc: 0.7399 - val_loss: 2.5331 - val_acc: 0.7421\n",
      "Epoch 10/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 2.4641 - acc: 0.7288 - val_loss: 2.4381 - val_acc: 0.7579\n",
      "Epoch 11/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 2.3689 - acc: 0.7571 - val_loss: 2.3478 - val_acc: 0.7842\n",
      "Epoch 12/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 2.2785 - acc: 0.7983 - val_loss: 2.2599 - val_acc: 0.8579\n",
      "Epoch 13/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 2.1930 - acc: 0.8380 - val_loss: 2.1790 - val_acc: 0.9105\n",
      "Epoch 14/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 2.1116 - acc: 0.9061 - val_loss: 2.1014 - val_acc: 0.9421\n",
      "Epoch 15/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 2.0342 - acc: 0.9216 - val_loss: 2.0282 - val_acc: 0.9632\n",
      "Epoch 16/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 1.9610 - acc: 0.9338 - val_loss: 1.9572 - val_acc: 0.9632\n",
      "Epoch 17/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 1.8913 - acc: 0.9388 - val_loss: 1.8915 - val_acc: 0.9632\n",
      "Epoch 18/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.8248 - acc: 0.9404 - val_loss: 1.8302 - val_acc: 0.9632\n",
      "Epoch 19/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.7620 - acc: 0.9410 - val_loss: 1.7697 - val_acc: 0.9632\n",
      "Epoch 20/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.7022 - acc: 0.9421 - val_loss: 1.7126 - val_acc: 0.9632\n",
      "Epoch 21/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 1.6450 - acc: 0.9435 - val_loss: 1.6610 - val_acc: 0.9632\n",
      "Epoch 22/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.5911 - acc: 0.9449 - val_loss: 1.6115 - val_acc: 0.9632\n",
      "Epoch 23/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 1.5399 - acc: 0.9504 - val_loss: 1.5610 - val_acc: 0.9632\n",
      "Epoch 24/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.4909 - acc: 0.9604 - val_loss: 1.5152 - val_acc: 0.9632\n",
      "Epoch 25/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.4441 - acc: 0.9576 - val_loss: 1.4703 - val_acc: 0.9632\n",
      "Epoch 26/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.3999 - acc: 0.9654 - val_loss: 1.4284 - val_acc: 0.9579\n",
      "Epoch 27/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.3571 - acc: 0.9670 - val_loss: 1.3883 - val_acc: 0.9579\n",
      "Epoch 28/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.3167 - acc: 0.9673 - val_loss: 1.3498 - val_acc: 0.9579\n",
      "Epoch 29/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 1.2786 - acc: 0.9706 - val_loss: 1.3129 - val_acc: 0.9579\n",
      "Epoch 30/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.2418 - acc: 0.9665 - val_loss: 1.2794 - val_acc: 0.9474\n",
      "Epoch 31/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.2063 - acc: 0.9673 - val_loss: 1.2460 - val_acc: 0.9526\n",
      "Epoch 32/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.1730 - acc: 0.9673 - val_loss: 1.2150 - val_acc: 0.9579\n",
      "Epoch 33/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.1411 - acc: 0.9734 - val_loss: 1.1840 - val_acc: 0.9526\n",
      "Epoch 34/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 1.1104 - acc: 0.9668 - val_loss: 1.1552 - val_acc: 0.9526\n",
      "Epoch 35/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 1.0810 - acc: 0.9695 - val_loss: 1.1270 - val_acc: 0.9579\n",
      "Epoch 36/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 1.0531 - acc: 0.9668 - val_loss: 1.1004 - val_acc: 0.9632\n",
      "Epoch 37/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 1.0261 - acc: 0.9801 - val_loss: 1.0762 - val_acc: 0.9737\n",
      "Epoch 38/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 1.0003 - acc: 0.9812 - val_loss: 1.0511 - val_acc: 0.9737\n",
      "Epoch 39/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.9757 - acc: 0.9859 - val_loss: 1.0265 - val_acc: 0.9789\n",
      "Epoch 40/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.9519 - acc: 0.9806 - val_loss: 1.0042 - val_acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd69f7860>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3610 samples, validate on 190 samples\n",
      "Epoch 1/40\n",
      "3610/3610 [==============================] - 0s 21us/step - loss: 0.9291 - acc: 0.9850 - val_loss: 0.9819 - val_acc: 0.9789\n",
      "Epoch 2/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.9074 - acc: 0.9867 - val_loss: 0.9613 - val_acc: 0.9737\n",
      "Epoch 3/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.8864 - acc: 0.9806 - val_loss: 0.9406 - val_acc: 0.9684\n",
      "Epoch 4/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.8663 - acc: 0.9837 - val_loss: 0.9212 - val_acc: 0.9737\n",
      "Epoch 5/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.8468 - acc: 0.9922 - val_loss: 0.9015 - val_acc: 0.9789\n",
      "Epoch 6/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.8280 - acc: 0.9823 - val_loss: 0.8848 - val_acc: 0.9684\n",
      "Epoch 7/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.8101 - acc: 0.9831 - val_loss: 0.8687 - val_acc: 0.9684\n",
      "Epoch 8/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.7925 - acc: 0.9886 - val_loss: 0.8509 - val_acc: 0.9737\n",
      "Epoch 9/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.7761 - acc: 0.9895 - val_loss: 0.8346 - val_acc: 0.9789\n",
      "Epoch 10/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.7597 - acc: 0.9889 - val_loss: 0.8187 - val_acc: 0.9789\n",
      "Epoch 11/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.7442 - acc: 0.9909 - val_loss: 0.8028 - val_acc: 0.9789\n",
      "Epoch 12/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.7290 - acc: 0.9837 - val_loss: 0.7900 - val_acc: 0.9684\n",
      "Epoch 13/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.7146 - acc: 0.9892 - val_loss: 0.7737 - val_acc: 0.9789\n",
      "Epoch 14/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.7006 - acc: 0.9837 - val_loss: 0.7605 - val_acc: 0.9789\n",
      "Epoch 15/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.6870 - acc: 0.9914 - val_loss: 0.7473 - val_acc: 0.9737\n",
      "Epoch 16/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.6739 - acc: 0.9917 - val_loss: 0.7331 - val_acc: 0.9789\n",
      "Epoch 17/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.6608 - acc: 0.9884 - val_loss: 0.7221 - val_acc: 0.9737\n",
      "Epoch 18/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.6484 - acc: 0.9900 - val_loss: 0.7095 - val_acc: 0.9789\n",
      "Epoch 19/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.6366 - acc: 0.9839 - val_loss: 0.6980 - val_acc: 0.9789\n",
      "Epoch 20/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.6247 - acc: 0.9920 - val_loss: 0.6861 - val_acc: 0.9789\n",
      "Epoch 21/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.6134 - acc: 0.9903 - val_loss: 0.6751 - val_acc: 0.9789\n",
      "Epoch 22/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.6025 - acc: 0.9909 - val_loss: 0.6652 - val_acc: 0.9789\n",
      "Epoch 23/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.5918 - acc: 0.9925 - val_loss: 0.6535 - val_acc: 0.9789\n",
      "Epoch 24/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.5814 - acc: 0.9903 - val_loss: 0.6444 - val_acc: 0.9789\n",
      "Epoch 25/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.5714 - acc: 0.9920 - val_loss: 0.6330 - val_acc: 0.9789\n",
      "Epoch 26/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.5616 - acc: 0.9925 - val_loss: 0.6227 - val_acc: 0.9789\n",
      "Epoch 27/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.5520 - acc: 0.9934 - val_loss: 0.6145 - val_acc: 0.9789\n",
      "Epoch 28/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.5427 - acc: 0.9928 - val_loss: 0.6049 - val_acc: 0.9789\n",
      "Epoch 29/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.5341 - acc: 0.9884 - val_loss: 0.5969 - val_acc: 0.9789\n",
      "Epoch 30/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.5251 - acc: 0.9928 - val_loss: 0.5867 - val_acc: 0.9789\n",
      "Epoch 31/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.5165 - acc: 0.9945 - val_loss: 0.5784 - val_acc: 0.9789\n",
      "Epoch 32/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.5082 - acc: 0.9922 - val_loss: 0.5703 - val_acc: 0.9789\n",
      "Epoch 33/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4999 - acc: 0.9931 - val_loss: 0.5632 - val_acc: 0.9789\n",
      "Epoch 34/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.4921 - acc: 0.9928 - val_loss: 0.5553 - val_acc: 0.9789\n",
      "Epoch 35/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4844 - acc: 0.9931 - val_loss: 0.5473 - val_acc: 0.9789\n",
      "Epoch 36/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.4767 - acc: 0.9934 - val_loss: 0.5397 - val_acc: 0.9789\n",
      "Epoch 37/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4694 - acc: 0.9934 - val_loss: 0.5314 - val_acc: 0.9789\n",
      "Epoch 38/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.4623 - acc: 0.9945 - val_loss: 0.5250 - val_acc: 0.9789\n",
      "Epoch 39/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4553 - acc: 0.9914 - val_loss: 0.5177 - val_acc: 0.9789\n",
      "Epoch 40/40\n",
      "3610/3610 [==============================] - 0s 20us/step - loss: 0.4483 - acc: 0.9939 - val_loss: 0.5105 - val_acc: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd69d9898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3610 samples, validate on 190 samples\n",
      "Epoch 1/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.4417 - acc: 0.9947 - val_loss: 0.5044 - val_acc: 0.9789\n",
      "Epoch 2/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4352 - acc: 0.9939 - val_loss: 0.4978 - val_acc: 0.9789\n",
      "Epoch 3/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4287 - acc: 0.9942 - val_loss: 0.4910 - val_acc: 0.9789\n",
      "Epoch 4/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.4226 - acc: 0.9939 - val_loss: 0.4851 - val_acc: 0.9789\n",
      "Epoch 5/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.4165 - acc: 0.9945 - val_loss: 0.4796 - val_acc: 0.9789\n",
      "Epoch 6/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.4104 - acc: 0.9928 - val_loss: 0.4725 - val_acc: 0.9789\n",
      "Epoch 7/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.4046 - acc: 0.9934 - val_loss: 0.4668 - val_acc: 0.9789\n",
      "Epoch 8/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3989 - acc: 0.9956 - val_loss: 0.4597 - val_acc: 0.9842\n",
      "Epoch 9/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3933 - acc: 0.9958 - val_loss: 0.4549 - val_acc: 0.9789\n",
      "Epoch 10/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3878 - acc: 0.9956 - val_loss: 0.4497 - val_acc: 0.9789\n",
      "Epoch 11/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3826 - acc: 0.9958 - val_loss: 0.4439 - val_acc: 0.9789\n",
      "Epoch 12/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3772 - acc: 0.9956 - val_loss: 0.4383 - val_acc: 0.9842\n",
      "Epoch 13/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3720 - acc: 0.9953 - val_loss: 0.4337 - val_acc: 0.9789\n",
      "Epoch 14/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3670 - acc: 0.9958 - val_loss: 0.4278 - val_acc: 0.9842\n",
      "Epoch 15/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3620 - acc: 0.9958 - val_loss: 0.4229 - val_acc: 0.9842\n",
      "Epoch 16/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.3573 - acc: 0.9953 - val_loss: 0.4177 - val_acc: 0.9842\n",
      "Epoch 17/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3524 - acc: 0.9961 - val_loss: 0.4130 - val_acc: 0.9842\n",
      "Epoch 18/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.3478 - acc: 0.9961 - val_loss: 0.4082 - val_acc: 0.9842\n",
      "Epoch 19/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.3434 - acc: 0.9958 - val_loss: 0.4022 - val_acc: 0.9895\n",
      "Epoch 20/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3387 - acc: 0.9961 - val_loss: 0.3989 - val_acc: 0.9842\n",
      "Epoch 21/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.3343 - acc: 0.9964 - val_loss: 0.3937 - val_acc: 0.9842\n",
      "Epoch 22/40\n",
      "3610/3610 [==============================] - 0s 22us/step - loss: 0.3299 - acc: 0.9961 - val_loss: 0.3903 - val_acc: 0.9842\n",
      "Epoch 23/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3258 - acc: 0.9961 - val_loss: 0.3860 - val_acc: 0.9842\n",
      "Epoch 24/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.3215 - acc: 0.9961 - val_loss: 0.3813 - val_acc: 0.9842\n",
      "Epoch 25/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3176 - acc: 0.9961 - val_loss: 0.3768 - val_acc: 0.9842\n",
      "Epoch 26/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3136 - acc: 0.9967 - val_loss: 0.3722 - val_acc: 0.9842\n",
      "Epoch 27/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.3097 - acc: 0.9961 - val_loss: 0.3683 - val_acc: 0.9842\n",
      "Epoch 28/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3058 - acc: 0.9964 - val_loss: 0.3655 - val_acc: 0.9842\n",
      "Epoch 29/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.3019 - acc: 0.9964 - val_loss: 0.3613 - val_acc: 0.9842\n",
      "Epoch 30/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2983 - acc: 0.9961 - val_loss: 0.3565 - val_acc: 0.9842\n",
      "Epoch 31/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2945 - acc: 0.9967 - val_loss: 0.3538 - val_acc: 0.9842\n",
      "Epoch 32/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2911 - acc: 0.9964 - val_loss: 0.3508 - val_acc: 0.9842\n",
      "Epoch 33/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2875 - acc: 0.9967 - val_loss: 0.3452 - val_acc: 0.9895\n",
      "Epoch 34/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2840 - acc: 0.9972 - val_loss: 0.3421 - val_acc: 0.9895\n",
      "Epoch 35/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2806 - acc: 0.9970 - val_loss: 0.3383 - val_acc: 0.9895\n",
      "Epoch 36/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2773 - acc: 0.9964 - val_loss: 0.3359 - val_acc: 0.9842\n",
      "Epoch 37/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2740 - acc: 0.9967 - val_loss: 0.3309 - val_acc: 0.9895\n",
      "Epoch 38/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2707 - acc: 0.9972 - val_loss: 0.3287 - val_acc: 0.9842\n",
      "Epoch 39/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2676 - acc: 0.9970 - val_loss: 0.3255 - val_acc: 0.9842\n",
      "Epoch 40/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2645 - acc: 0.9967 - val_loss: 0.3225 - val_acc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd444c860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3610 samples, validate on 190 samples\n",
      "Epoch 1/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.2614 - acc: 0.9970 - val_loss: 0.3186 - val_acc: 0.9895\n",
      "Epoch 2/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2583 - acc: 0.9970 - val_loss: 0.3157 - val_acc: 0.9895\n",
      "Epoch 3/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.2553 - acc: 0.9964 - val_loss: 0.3128 - val_acc: 0.9895\n",
      "Epoch 4/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.2524 - acc: 0.9972 - val_loss: 0.3088 - val_acc: 0.9895\n",
      "Epoch 5/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.2496 - acc: 0.9972 - val_loss: 0.3059 - val_acc: 0.9895\n",
      "Epoch 6/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.2467 - acc: 0.9967 - val_loss: 0.3038 - val_acc: 0.9895\n",
      "Epoch 7/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2439 - acc: 0.9975 - val_loss: 0.2996 - val_acc: 0.9895\n",
      "Epoch 8/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.2412 - acc: 0.9972 - val_loss: 0.2973 - val_acc: 0.9895\n",
      "Epoch 9/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2384 - acc: 0.9972 - val_loss: 0.2945 - val_acc: 0.9895\n",
      "Epoch 10/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.2359 - acc: 0.9975 - val_loss: 0.2909 - val_acc: 0.9895\n",
      "Epoch 11/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2332 - acc: 0.9978 - val_loss: 0.2887 - val_acc: 0.9895\n",
      "Epoch 12/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2306 - acc: 0.9978 - val_loss: 0.2871 - val_acc: 0.9895\n",
      "Epoch 13/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2280 - acc: 0.9972 - val_loss: 0.2845 - val_acc: 0.9895\n",
      "Epoch 14/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2256 - acc: 0.9975 - val_loss: 0.2814 - val_acc: 0.9895\n",
      "Epoch 15/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.2231 - acc: 0.9978 - val_loss: 0.2784 - val_acc: 0.9895\n",
      "Epoch 16/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2206 - acc: 0.9975 - val_loss: 0.2762 - val_acc: 0.9895\n",
      "Epoch 17/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2182 - acc: 0.9975 - val_loss: 0.2739 - val_acc: 0.9895\n",
      "Epoch 18/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2160 - acc: 0.9978 - val_loss: 0.2709 - val_acc: 0.9895\n",
      "Epoch 19/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.2137 - acc: 0.9975 - val_loss: 0.2685 - val_acc: 0.9895\n",
      "Epoch 20/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.2114 - acc: 0.9975 - val_loss: 0.2670 - val_acc: 0.9895\n",
      "Epoch 21/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2091 - acc: 0.9978 - val_loss: 0.2645 - val_acc: 0.9895\n",
      "Epoch 22/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2069 - acc: 0.9978 - val_loss: 0.2617 - val_acc: 0.9895\n",
      "Epoch 23/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.2048 - acc: 0.9978 - val_loss: 0.2582 - val_acc: 0.9947\n",
      "Epoch 24/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.2026 - acc: 0.9978 - val_loss: 0.2580 - val_acc: 0.9895\n",
      "Epoch 25/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.2005 - acc: 0.9975 - val_loss: 0.2544 - val_acc: 0.9895\n",
      "Epoch 26/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1984 - acc: 0.9975 - val_loss: 0.2525 - val_acc: 0.9895\n",
      "Epoch 27/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1963 - acc: 0.9978 - val_loss: 0.2506 - val_acc: 0.9895\n",
      "Epoch 28/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1943 - acc: 0.9981 - val_loss: 0.2485 - val_acc: 0.9895\n",
      "Epoch 29/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1924 - acc: 0.9972 - val_loss: 0.2470 - val_acc: 0.9895\n",
      "Epoch 30/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1904 - acc: 0.9981 - val_loss: 0.2438 - val_acc: 0.9947\n",
      "Epoch 31/40\n",
      "3610/3610 [==============================] - 0s 22us/step - loss: 0.1884 - acc: 0.9981 - val_loss: 0.2428 - val_acc: 0.9895\n",
      "Epoch 32/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1865 - acc: 0.9981 - val_loss: 0.2411 - val_acc: 0.9895\n",
      "Epoch 33/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1847 - acc: 0.9978 - val_loss: 0.2384 - val_acc: 0.9895\n",
      "Epoch 34/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1828 - acc: 0.9983 - val_loss: 0.2355 - val_acc: 0.9947\n",
      "Epoch 35/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1810 - acc: 0.9983 - val_loss: 0.2339 - val_acc: 0.9947\n",
      "Epoch 36/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1791 - acc: 0.9983 - val_loss: 0.2321 - val_acc: 0.9947\n",
      "Epoch 37/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1773 - acc: 0.9983 - val_loss: 0.2302 - val_acc: 0.9947\n",
      "Epoch 38/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1756 - acc: 0.9983 - val_loss: 0.2288 - val_acc: 0.9895\n",
      "Epoch 39/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1738 - acc: 0.9981 - val_loss: 0.2272 - val_acc: 0.9895\n",
      "Epoch 40/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1722 - acc: 0.9983 - val_loss: 0.2251 - val_acc: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd444c400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3610 samples, validate on 190 samples\n",
      "Epoch 1/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1705 - acc: 0.9983 - val_loss: 0.2228 - val_acc: 0.9947\n",
      "Epoch 2/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1688 - acc: 0.9983 - val_loss: 0.2212 - val_acc: 0.9947\n",
      "Epoch 3/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1671 - acc: 0.9983 - val_loss: 0.2203 - val_acc: 0.9895\n",
      "Epoch 4/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1655 - acc: 0.9983 - val_loss: 0.2177 - val_acc: 0.9947\n",
      "Epoch 5/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1639 - acc: 0.9983 - val_loss: 0.2160 - val_acc: 0.9947\n",
      "Epoch 6/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1624 - acc: 0.9983 - val_loss: 0.2143 - val_acc: 0.9947\n",
      "Epoch 7/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1608 - acc: 0.9981 - val_loss: 0.2130 - val_acc: 0.9947\n",
      "Epoch 8/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1593 - acc: 0.9983 - val_loss: 0.2104 - val_acc: 0.9947\n",
      "Epoch 9/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1579 - acc: 0.9983 - val_loss: 0.2099 - val_acc: 0.9947\n",
      "Epoch 10/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1562 - acc: 0.9983 - val_loss: 0.2084 - val_acc: 0.9947\n",
      "Epoch 11/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1548 - acc: 0.9983 - val_loss: 0.2059 - val_acc: 0.9947\n",
      "Epoch 12/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1534 - acc: 0.9983 - val_loss: 0.2059 - val_acc: 0.9947\n",
      "Epoch 13/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1519 - acc: 0.9983 - val_loss: 0.2029 - val_acc: 0.9947\n",
      "Epoch 14/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1505 - acc: 0.9983 - val_loss: 0.2026 - val_acc: 0.9947\n",
      "Epoch 15/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1491 - acc: 0.9983 - val_loss: 0.2013 - val_acc: 0.9947\n",
      "Epoch 16/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1477 - acc: 0.9983 - val_loss: 0.1994 - val_acc: 0.9947\n",
      "Epoch 17/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1464 - acc: 0.9983 - val_loss: 0.1977 - val_acc: 0.9947\n",
      "Epoch 18/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1451 - acc: 0.9983 - val_loss: 0.1970 - val_acc: 0.9947\n",
      "Epoch 19/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1437 - acc: 0.9983 - val_loss: 0.1947 - val_acc: 0.9947\n",
      "Epoch 20/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1424 - acc: 0.9983 - val_loss: 0.1938 - val_acc: 0.9947\n",
      "Epoch 21/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1411 - acc: 0.9983 - val_loss: 0.1930 - val_acc: 0.9947\n",
      "Epoch 22/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1399 - acc: 0.9986 - val_loss: 0.1908 - val_acc: 0.9947\n",
      "Epoch 23/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1386 - acc: 0.9983 - val_loss: 0.1902 - val_acc: 0.9947\n",
      "Epoch 24/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1374 - acc: 0.9983 - val_loss: 0.1880 - val_acc: 0.9947\n",
      "Epoch 25/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1361 - acc: 0.9983 - val_loss: 0.1863 - val_acc: 0.9947\n",
      "Epoch 26/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1348 - acc: 0.9983 - val_loss: 0.1854 - val_acc: 0.9947\n",
      "Epoch 27/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1337 - acc: 0.9983 - val_loss: 0.1838 - val_acc: 0.9947\n",
      "Epoch 28/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1325 - acc: 0.9983 - val_loss: 0.1828 - val_acc: 0.9947\n",
      "Epoch 29/40\n",
      "3610/3610 [==============================] - 0s 15us/step - loss: 0.1313 - acc: 0.9983 - val_loss: 0.1817 - val_acc: 0.9947\n",
      "Epoch 30/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1303 - acc: 0.9983 - val_loss: 0.1801 - val_acc: 0.9947\n",
      "Epoch 31/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1291 - acc: 0.9983 - val_loss: 0.1786 - val_acc: 0.9947\n",
      "Epoch 32/40\n",
      "3610/3610 [==============================] - 0s 18us/step - loss: 0.1280 - acc: 0.9983 - val_loss: 0.1784 - val_acc: 0.9947\n",
      "Epoch 33/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1269 - acc: 0.9983 - val_loss: 0.1772 - val_acc: 0.9947\n",
      "Epoch 34/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1257 - acc: 0.9983 - val_loss: 0.1754 - val_acc: 0.9947\n",
      "Epoch 35/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1246 - acc: 0.9983 - val_loss: 0.1745 - val_acc: 0.9947\n",
      "Epoch 36/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1236 - acc: 0.9983 - val_loss: 0.1729 - val_acc: 0.9947\n",
      "Epoch 37/40\n",
      "3610/3610 [==============================] - 0s 17us/step - loss: 0.1225 - acc: 0.9983 - val_loss: 0.1718 - val_acc: 0.9947\n",
      "Epoch 38/40\n",
      "3610/3610 [==============================] - 0s 19us/step - loss: 0.1215 - acc: 0.9983 - val_loss: 0.1720 - val_acc: 0.9947\n",
      "Epoch 39/40\n",
      "3610/3610 [==============================] - 0s 14us/step - loss: 0.1204 - acc: 0.9983 - val_loss: 0.1704 - val_acc: 0.9947\n",
      "Epoch 40/40\n",
      "3610/3610 [==============================] - 0s 16us/step - loss: 0.1195 - acc: 0.9983 - val_loss: 0.1695 - val_acc: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd444c080>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 40, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"svr_all_symbols.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('svr_all_symbols.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('svr_all_symbols.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "test_data_sample = X_val[sample_number].reshape(1, 13)\n",
    "test_data_actual_label = y_val[sample_number]\n",
    "\n",
    "print(test_data_sample.shape)\n",
    "print(test_data_actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62      , 0.77      , 0.13      , 0.96078431, 0.37647059,\n",
       "        0.18823529, 0.24313725, 0.21568627, 0.82600196, 0.        ,\n",
       "        1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob = model1.predict(test_data_sample)\n",
    "predicted_label = np.argmax(predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2837786e-07 6.3570167e-07 4.6185650e-07 5.5886853e-06 1.3363700e-04\n",
      "  2.0758653e-06 2.0642201e-03 8.9082599e-01 3.9847014e-06 2.9707438e-05\n",
      "  5.6112872e-04 1.8334655e-03 5.8661408e-07 8.6344029e-05 1.6232554e-05\n",
      "  1.3309189e-04 3.1630714e-06 5.5917750e-05 1.1115768e-08 1.5510247e-03\n",
      "  2.9647523e-03 3.0610463e-05 3.6951781e-06 3.2228993e-06 4.4926396e-06\n",
      "  3.4224828e-05 1.8041219e-07 5.3309362e-02 6.5637727e-07 2.6368059e-02\n",
      "  4.7220710e-05 2.5567999e-03 2.3800139e-06 1.0326248e-05 9.8992117e-05\n",
      "  1.5124303e-03 8.5154761e-07 1.0535559e-09 2.8890668e-07 3.0087730e-07\n",
      "  6.3333744e-07 1.1201477e-06 2.0830185e-04 1.5533649e-02]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(predicted_prob)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890826"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob[0][predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
